version: '3'

services:
  zookeeper:
    image: confluentinc/cp-zookeeper:7.0.0
    hostname: zookeeper
    container_name: zookeeper
    ports:
      - "22181:2181"
    environment:
      ZOOKEEPER_SERVER_ID: 1 #주키퍼를 식별하는 아이디로 유일한 값, 1개의 주키퍼를 사용할 예정이라 없어도 문제없음
      ZOOKEEPER_CLIENT_PORT: 2181 #주키퍼 포트, 기본 포트로 2181사용
      ZOOKEEPER_TICK_TIME: 2000 #클러스터를 구성할 때 동기화를 위한 기본 틱 타임

  # 여러 broker 혹은 zookeeper를 할경우 아래처럼 추가해주면 됨(포트번호는 앞 부분의 숫자만 바꿔주면 됨)
  # zookeeper-2:
  #   image: confluentinc/cp-zookeeper:7.0.0
  #   hostname: zookeeper
  #   container_name: zookeeper_2
  #   ports:
  #     - "32181:2181"
  #   environment:
  #     ZOOKEEPER_SERVER_ID: 1 #주키퍼를 식별하는 아이디로 유일한 값, 1개의 주키퍼를 사용할 예정이라 없어도 문제없음
  #     ZOOKEEPER_CLIENT_PORT: 2181 #주키퍼 포트, 기본 포트로 2181사용
  #     ZOOKEEPER_TICK_TIME: 2000 #클러스터를 구성할 때 동기화를 위한 기본 틱 타임


  broker:
    image: confluentinc/cp-kafka:7.0.0
    container_name: broker
    hostname: broker
    ports:
      - "9092:9092"
    depends_on: #아래 컨테이너가 정상적으로 빌드&실행이 됐으면 이 컨테이너도 생성됨
      - zookeeper
    environment:
      KAFKA_BROKER_ID: 1 
      KAFKA_ZOOKEEPER_CONNECT: 'zookeeper:2181' #주키퍼에 연결하기 위한 대상 지정 (hostname:port)
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: "INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT" #보안을 위한 프로토콜 매핑. PLAINTEXT는 암호화하지 않은 일반 평문
      KAFKA_ADVERTISED_LISTENERS: "INTERNAL://broker:29092,EXTERNAL://localhost:9092" # 외부 클라이언트 리스너 주소
      KAFKA_INTER_BROKER_LISTENER_NAME: "INTERNAL"
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 3 #브로커 복제 개수 옵션
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1 #트랜젝션 최소 ISR(InSyncReplicas 설정) 수
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 3 #트렌젝션 상태에서 복제 수
      KAFKA_HEARTBEAT_INTERVAL_MS: 3000 #컨슈머가 주키퍼에 하트비트를 보내는 주기가 짧아짐 너무 길면 컨슈머가 dead됐다고 인식하고 리밸런싱하게됨
      KAFKA_SESSION_TIMEOUT_MS: 10000 #리밸런싱으로 인해 세션시간을 늘려야 실패한 소비자로 그룹제거를 하고 재조정할 시간을 벌어준다.

  # broker-2:
  #   image: confluentinc/cp-kafka:7.0.0
  #   container_name: broker_2
  #   hostname: broker
  #   ports:
  #     - "9092:9092"
  #   depends_on:
  #     - zookeeper
  #   environment:
  #     KAFKA_BROKER_ID: 1 
  #     KAFKA_ZOOKEEPER_CONNECT: 'zookeeper:2181' #주키퍼에 연결하기 위한 대상 지정 (hostname:port)
  #     KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: "INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT" #보안을 위한 프로토콜 매핑. PLAINTEXT는 암호화하지 않은 일반 평문
  #     KAFKA_ADVERTISED_LISTENERS: "INTERNAL://broker:29092,EXTERNAL://localhost:9092" # 외부 클라이언트 리스너 주소
  #     KAFKA_INTER_BROKER_LISTENER_NAME: "INTERNAL"
  #     KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1 #토픽 파티션 복제에 대한 설정 값
  #     KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1 #트랜젝션 최소 ISR(InSyncReplicas 설정) 수
  #     KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1 #트렌젝션 상태에서 복제 수
  #     KAFKA_HEARTBEAT_INTERVAL_MS: 3000 #컨슈머가 주키퍼에 하트비트를 보내는 주기가 짧아짐 너무 길면 컨슈머가 dead됐다고 인식하고 리밸런싱하게됨
  #     KAFKA_SESSION_TIMEOUT_MS: 10000 #리밸런싱으로 인해 세션시간을 늘려야 실패한 소비자로 그룹제거를 하고 재조정할 시간을 벌어준다.


  # 시각화 컨테이너(선택)
  kafdrop:
    image: obsidiandynamics/kafdrop
    container_name: kafka_ui
    restart: "always"
    ports:
      - "9000:9000"
    depends_on:
      - broker
      - zookeeper
    environment:
      KAFKA_BROKERCONNECT: 'broker:29092' #여러개면 broker-2:29092,broker-3:29092,...
      JVM_OPTS: "-Xms32M -Xmx64M"


#컨테이너들 한번에 삭제
# docker rm -f $(docker ps -qa)